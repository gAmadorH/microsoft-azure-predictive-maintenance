apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlflow-inference
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mlflow-inference
  template:
    metadata:
      labels:
        app: mlflow-inference
    spec:
      containers:
        - name: api
          image: mlflow-fastapi:latest # change it if your local image has another name
          imagePullPolicy: Always
          ports:
            - containerPort: 8000
          envFrom:
            - secretRef:
                name: mlflow-tracking
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 20
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
          securityContext:
            allowPrivilegeEscalation: false
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
---
apiVersion: v1
kind: Service
metadata:
  name: mlflow-inference-lb
  namespace: default
spec:
  type: LoadBalancer
  selector:
    app: mlflow-inference
  ports:
    - name: http
      port: 8000
      targetPort: 8000
